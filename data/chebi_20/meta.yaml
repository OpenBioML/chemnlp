---
name: chebi_20
description: A dataset of pairs of natural language descriptions and SMILEs.
targets:
    - id: description
      description: a natural language description of the molecule SMILE
      units:
      type: string
      names:
          - noun: natural language description
      pubchem_aids: []
      uris: []
identifiers:
    - id: SMILES
      type: SMILES
      description: SMILES
    - id: compound_id
      type: Other
      names:
          - compound id
      sample: false
      description: This is the PubChem CID to identify a given molecule.
license: CC BY 4.0
links:
    - name: Research Paper
      url: https://aclanthology.org/2021.emnlp-main.47/
      description: Original Text2Mol paper which introduced the chebi_20 dataset.
    - name: Dataset
      url: https://github.com/cnedwards/text2mol
      description: Text2Mol original data repository on GitHub.
    - name: Hugging Face dataset upload
      url: https://huggingface.co/datasets/OpenBioML/chebi_20
      description: Hugging Face dataset uploaded to the OpenBioML organisation.
benchmarks: []
num_points: 33008
bibtex:
    - |-
      @inproceedings{edwards2021text2mol,
                  title={Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries},
                  author={Edwards, Carl and Zhai, ChengXiang and Ji, Heng},
                  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
                  pages={595--607},
                  year={2021},
                  url = {https://aclanthology.org/2021.emnlp-main.47/}
                  }
    - |-
      @inproceedings{edwards-etal-2022-translation,
                  title = "Translation between Molecules and Natural Language",
                  author = "Edwards, Carl  and
                      Lai, Tuan  and
                      Ros, Kevin  and
                      Honke, Garrett  and
                      Cho, Kyunghyun  and
                      Ji, Heng",
                  booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
                  month = dec,
                  year = "2022",
                  address = "Abu Dhabi, United Arab Emirates",
                  publisher = "Association for Computational Linguistics",
                  url = "https://aclanthology.org/2022.emnlp-main.26",
                  pages = "375--413",
                  abstract = "We present MolT5 - a self-supervised learning framework for pretraining models on a vast amount of unlabeled natural language text and molecule strings. MolT5 allows for new, useful, and challenging analogs of traditional vision-language tasks, such as molecule captioning and text-based de novo molecule generation (altogether: translation between molecules and language), which we explore for the first time. Since MolT5 pretrains models on single-modal data, it helps overcome the chemistry domain shortcoming of data scarcity. Furthermore, we consider several metrics, including a new cross-modal embedding-based metric, to evaluate the tasks of molecule captioning and text-based molecule generation. Our results show that MolT5-based models are able to generate outputs, both molecules and captions, which in many cases are high quality.",
                  }
